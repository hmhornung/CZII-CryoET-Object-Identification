{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickable objects in this project:\n",
      "  apo-ferritin: 1\n",
      "  beta-amylase: 2\n",
      "  beta-galactosidase: 3\n",
      "  ribosome: 4\n",
      "  thyroglobulin: 5\n",
      "  virus-like-particle: 6\n",
      "  membrane: 8\n",
      "  background: 9\n",
      "Runs in this project:\n",
      "Run: TS_5_4\n",
      "Run: TS_69_2\n",
      "Run: TS_6_4\n",
      "Run: TS_6_6\n",
      "Run: TS_73_6\n",
      "Run: TS_86_3\n",
      "Run: TS_99_9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Print all objects and runs in a copick project.\"\"\"\n",
    "\n",
    "import copick\n",
    "\n",
    "# Initialize the root object from a configuration file\n",
    "root = copick.from_file(\"copick_config.json\")\n",
    "\n",
    "# List all available objects\n",
    "obj_info = [(o.name, o.label) for o in root.pickable_objects]\n",
    "\n",
    "print(\"Pickable objects in this project:\")\n",
    "for name, label in obj_info:\n",
    "    print(f\"  {name}: {label}\")\n",
    "\n",
    "# Execute a function on each run in the project\n",
    "runs = root.runs\n",
    "\n",
    "print(\"Runs in this project:\")\n",
    "for run in runs:\n",
    "    print(f\"Run: {run.name}\")\n",
    "    # Do something with the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resolution level 0 from path '0'...\n",
      "Loading resolution level 1 from path '1'...\n",
      "Loading resolution level 2 from path '2'...\n",
      "Resolution level_0: data shape = (184, 630, 630)\n",
      "Resolution level_1: data shape = (92, 315, 315)\n",
      "Resolution level_2: data shape = (46, 158, 158)\n",
      "Loaded particles and coordinates:\n",
      "  apo-ferritin: 95 coordinates loaded\n",
      "  beta-amylase: 12 coordinates loaded\n",
      "  beta-galactosidase: 14 coordinates loaded\n",
      "  ribosome: 46 coordinates loaded\n",
      "  thyroglobulin: 28 coordinates loaded\n",
      "  virus-like-particle: 22 coordinates loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import zarr\n",
    "import copick\n",
    "\n",
    "# Paths\n",
    "config_path = \"copick_config.json\"\n",
    "data_root = \"../data/train/static/ExperimentRuns\"\n",
    "\n",
    "# Load the configuration\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "static_root = config[\"static_root\"]\n",
    "overlay_root = config[\"overlay_root\"]\n",
    "\n",
    "# Function to load CryoET OME-Zarr data at all resolutions\n",
    "def load_cryoet_omezarr_data_all_resolutions(experiment, particle_types):\n",
    "    zarr_path = os.path.join(static_root, f\"ExperimentRuns/{experiment}/VoxelSpacing10.000/denoised.zarr\")\n",
    "    picks_path = os.path.join(overlay_root, f\"ExperimentRuns/{experiment}/Picks\")\n",
    "    \n",
    "    # Open the OME-Zarr dataset\n",
    "    store = zarr.DirectoryStore(zarr_path)\n",
    "    root = zarr.open(store, mode='r')\n",
    "\n",
    "    # Check for multiscales metadata\n",
    "    if \"multiscales\" not in root.attrs:\n",
    "        raise ValueError(\"This Zarr file does not contain OME-Zarr multiscales metadata.\")\n",
    "    \n",
    "    # Retrieve metadata for multiscale levels\n",
    "    multiscales = root.attrs[\"multiscales\"]\n",
    "    datasets = multiscales[0][\"datasets\"]  # Assuming one multiscale entry\n",
    "\n",
    "    # Load data at each resolution level\n",
    "    resolution_data = {}\n",
    "    for idx, dataset in enumerate(datasets):\n",
    "        data_path = dataset[\"path\"]\n",
    "        print(f\"Loading resolution level {idx} from path '{data_path}'...\")\n",
    "        resolution_data[f\"level_{idx}\"] = root[data_path][:]\n",
    "    \n",
    "    # Load ground truth JSONs (particle coordinates)\n",
    "    particle_coords = {}\n",
    "    for particle in particle_types:\n",
    "        json_path = os.path.join(picks_path, f\"{particle}.json\")\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                particle_coords[particle] = json.load(f)\n",
    "        else:\n",
    "            print(f\"Ground truth file for {particle} not found.\")\n",
    "    \n",
    "    return resolution_data, particle_coords\n",
    "\n",
    "# Example usage\n",
    "experiment_name = \"TS_73_6\"  # Replace with the actual experiment name\n",
    "particle_types = [obj[\"name\"] for obj in config[\"pickable_objects\"] if obj[\"is_particle\"]]\n",
    "\n",
    "# Load dataset\n",
    "tomographic_data_by_resolution, ground_truth = load_cryoet_omezarr_data_all_resolutions(experiment_name, particle_types)\n",
    "\n",
    "# Display loaded data\n",
    "for resolution, tomo_data in tomographic_data_by_resolution.items():\n",
    "    print(f\"Resolution {resolution}: data shape = {tomo_data.shape}\")\n",
    "\n",
    "print(\"Loaded particles and coordinates:\")\n",
    "for name, data in ground_truth.items():\n",
    "    num_coords = len(data[\"points\"])\n",
    "    print(f\"  {name}: {num_coords} coordinates loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "coordinates_array = np.array([[p['location']['x'], p['location']['y'], p['location']['z']] \n",
    "                              for v in ground_truth.values() for p in v['points']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6183.204\n",
      "6098.949\n",
      "1335.552\n"
     ]
    }
   ],
   "source": [
    "print(coordinates_array[:,0].max())\n",
    "print(coordinates_array[:,1].max())\n",
    "print(coordinates_array[:,2].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_and_augment(volume, coordinates, target_resolution=(1.0, 1.0, 1.0)):\n",
    "    \"\"\"\n",
    "    Preprocess and augment a 3D volume with a list of coordinates using TorchIO.\n",
    "    \n",
    "    Parameters:\n",
    "        volume (np.ndarray): Input 3D volume.\n",
    "        coordinates (np.ndarray): Array of 3D coordinates (N x 3).\n",
    "        target_resolution (tuple): Target resolution for resampling (default is placeholder).\n",
    "\n",
    "    Returns:\n",
    "        augmented_volume (np.ndarray): Augmented volume.\n",
    "        transformed_coordinates (np.ndarray): Transformed 3D coordinates.\n",
    "    \"\"\"\n",
    "    # Ensure coordinates are a numpy array\n",
    "    coordinates = np.asarray(coordinates)\n",
    "    \n",
    "    # Normalize the volume\n",
    "    volume_tensor = tio.ScalarImage(tensor=volume[np.newaxis, ...])\n",
    "    volume_normalized = tio.transforms.ZNormalization()(volume_tensor)\n",
    "    \n",
    "    # Resample to the target resolution\n",
    "    resample_transform = tio.Resample(target_resolution)\n",
    "    volume_resampled = resample_transform(volume_normalized)\n",
    "    coordinates = resample_transform.apply_to_points(coordinates)\n",
    "    \n",
    "    # Calculate new dimensions for zero-padding\n",
    "    original_shape = volume_resampled.shape[1:]  # Exclude the channel axis\n",
    "    max_dim = int(np.ceil(np.sqrt(2) * max(original_shape)))\n",
    "    padded_shape = (max_dim, max_dim, max_dim)\n",
    "    \n",
    "    # Center the volume and coordinates with zero-padding\n",
    "    pad_transform = tio.CropOrPad(padded_shape)\n",
    "    volume_padded = pad_transform(volume_resampled)\n",
    "    coordinates = pad_transform.apply_to_points(coordinates)\n",
    "    \n",
    "    # Apply random flip\n",
    "    flip_transform = tio.RandomFlip(axes=(0, 1, 2))\n",
    "    volume_flipped = flip_transform(volume_padded)\n",
    "    coordinates = flip_transform.apply_to_points(coordinates)\n",
    "    \n",
    "    # Apply random rotation\n",
    "    rotation_transform = tio.RandomAffine(scales=1, degrees=(0, 45), isotropic=False)\n",
    "    volume_rotated = rotation_transform(volume_flipped)\n",
    "    coordinates = rotation_transform.apply_to_points(coordinates)\n",
    "    \n",
    "    # Extract the final augmented volume as a numpy array\n",
    "    augmented_volume = volume_rotated.tensor.numpy()[0]  # Remove channel axis\n",
    "    \n",
    "    return augmented_volume, coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2063562566434f21bb8ee4caaa1def0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=108, description='i', max=216), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_cross_section(i)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Assuming `volume` is your 3D data array (replace with your actual data volume)\n",
    "# coordinates_array is extracted from the earlier numpy code\n",
    "level = 0\n",
    "\n",
    "volume = tomographic_data_by_resolution[f'level_{level}']\n",
    "\n",
    "scale = 10 * (2**level)\n",
    "\n",
    "adjusted_coords = (np.array(coordinates_array)[:, [2, 1, 0]] ) / scale\n",
    "\n",
    "\n",
    "def plot_cross_section(i):\n",
    "    # Determine slicing planes (current x, y, z coordinates for index)\n",
    "    \n",
    "    coords = adjusted_coords\n",
    "    x_coord = int(coords[i, 0])\n",
    "    y_coord = int(coords[i, 1])\n",
    "    z_coord = int(coords[i, 2])\n",
    "    \n",
    "    # Create 3D cross-section plots with only the current coordinate visualized\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Slice at x-coordinate\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(volume[x_coord, :, :], cmap=\"viridis\")\n",
    "    plt.scatter(z_coord, y_coord, color='red', s=2)  # Map y, z in this slice\n",
    "    plt.title(f'Slice at x={x_coord}')\n",
    "\n",
    "    # Slice at y-coordinate\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(volume[:, y_coord, :], cmap=\"viridis\")\n",
    "    plt.scatter(z_coord, x_coord, color='red', s=2)  # Map x, z in this slice\n",
    "    plt.title(f'Slice at y={y_coord}')\n",
    "\n",
    "    # Slice at z-coordinate\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(volume[:, :, z_coord], cmap=\"viridis\")\n",
    "    plt.scatter(y_coord, x_coord, color='red', s=2)  # Map x, y in this slice\n",
    "    plt.title(f'Slice at z={z_coord}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Interactive Slider for scrolling through slices\n",
    "interact(plot_cross_section, i=(0, len(coordinates_array) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
