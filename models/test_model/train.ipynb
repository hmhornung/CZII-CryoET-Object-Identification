{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as torch_split\n",
    "import numpy as np\n",
    "import dataset\n",
    "import test\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet\n",
    "from monai.data import DataLoader\n",
    "import sys\n",
    "sys.path.insert(1, 'H:/Projects/Kaggle/CZII-CryoET-Object-Identification/preprocessing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"H:/Projects/Kaggle/CZII-CryoET-Object-Identification/datasets/3D/dim96-no-corner\"\n",
    "data = dataset.UNetDataset(path=path)\n",
    "\n",
    "tv_split = 0.8\n",
    "trn = int(len(data) * tv_split)\n",
    "val = len(data) - trn\n",
    "\n",
    "train_dataset, val_dataset = torch_split.random_split(data, [trn, val])\n",
    "# train_dataset = dataset.UNetDataset(path=path, train=True)\n",
    "# val_dataset = dataset.UNetDataset(path=path, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\monai\\networks\\nets\\unet.py:130: UserWarning: `len(strides) > len(channels) - 1`, the last 1 values of strides will not be used.\n",
      "  warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.9324, Val Loss: 0.9155\n",
      "Epoch 2/20 - Train Loss: 0.9022, Val Loss: 0.8855\n",
      "Epoch 3/20 - Train Loss: 0.8724, Val Loss: 0.8632\n",
      "Epoch 4/20 - Train Loss: 0.8407, Val Loss: 0.8252\n",
      "Epoch 5/20 - Train Loss: 0.8110, Val Loss: 0.8009\n",
      "Epoch 6/20 - Train Loss: 0.7848, Val Loss: 0.7800\n",
      "Epoch 7/20 - Train Loss: 0.7673, Val Loss: 0.7715\n",
      "Epoch 8/20 - Train Loss: 0.7522, Val Loss: 0.7602\n",
      "Epoch 9/20 - Train Loss: 0.7394, Val Loss: 0.7544\n",
      "Epoch 10/20 - Train Loss: 0.7275, Val Loss: 0.7447\n",
      "Epoch 11/20 - Train Loss: 0.7183, Val Loss: 0.7360\n",
      "Epoch 12/20 - Train Loss: 0.7012, Val Loss: 0.7247\n",
      "Epoch 13/20 - Train Loss: 0.6870, Val Loss: 0.7243\n",
      "Epoch 14/20 - Train Loss: 0.6742, Val Loss: 0.7162\n",
      "Epoch 15/20 - Train Loss: 0.6617, Val Loss: 0.6999\n",
      "Epoch 16/20 - Train Loss: 0.6460, Val Loss: 0.6945\n",
      "Epoch 17/20 - Train Loss: 0.6377, Val Loss: 0.6918\n",
      "Epoch 18/20 - Train Loss: 0.6265, Val Loss: 0.6927\n",
      "Epoch 19/20 - Train Loss: 0.6224, Val Loss: 0.6925\n",
      "Epoch 20/20 - Train Loss: 0.6053, Val Loss: 0.6877\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model initialization\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,  # Assuming single-channel input (adjust as needed)\n",
    "    out_channels=7,  # Assuming 7 classes for segmentation (adjust as needed)\n",
    "    channels=(64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "# model = test.UNet3D(in_channels = 1, out_channels = 7)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = DiceLoss(to_onehot_y=True, softmax=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers = 4, collate_fn=dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers = 4, collate_fn=dataset.collate_fn)\n",
    "\n",
    "n_batch = 5\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    n = 0\n",
    "    c_loss = 0\n",
    "    for batch in train_loader:\n",
    "        n += 1\n",
    "        inputs, targets = batch['src'].float().to(device), batch['tgt'].long().to(device)\n",
    "        # print(inputs.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # c_loss += loss.item()\n",
    "        # if n % n_batch == 0:\n",
    "        #     print(f\"batch {n-n_batch}-{n} train loss: {c_loss}\")\n",
    "        #     c_loss = 0\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            n += 1\n",
    "            inputs, targets = batch['src'].float().to(device), batch['tgt'].long().to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # print(f\"validation batch {n} done\")\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "import augment\n",
    "import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "root = load.get_root()\n",
    "\n",
    "picks = load.get_picks_dict(root)\n",
    "\n",
    "vol, coords, scales = load.get_run_volume_picks(root, level=0)\n",
    "\n",
    "mask = load.get_picks_mask(vol.shape, picks, coords, int(scales[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Particles Types Represented: 4\n",
      "# Particles Types Predicted: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6cbda450ab4f658c008fe129d572b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=47, description='i', max=95), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_cross_section(i)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = augment.aug_params\n",
    "params['patch_size'] = (96,96,96)\n",
    "params['final_size'] = (96,96,96)\n",
    "params['flip_prob'] - 0.0\n",
    "params['rot_prob'] = 0.0\n",
    "params['rot_range'] = 0.0\n",
    "\n",
    "\n",
    "\n",
    "samples = augment.random_augmentation(vol, mask, num_samples=1, aug_params=params)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inp = np.array(samples[0][\"source\"].unsqueeze(0).unsqueeze(0))\n",
    "inp = torch.from_numpy(inp).to(device)\n",
    "pred_mask = model(inp)\n",
    "\n",
    "src = samples[0]['source']\n",
    "tgt = samples[0]['target']  # Mask with interest points (non-zero values)\n",
    "\n",
    "pred_tgt = pred_mask.squeeze().cpu().detach()\n",
    "\n",
    "\n",
    "pred_tgt = torch.argmax(pred_tgt, dim = 0).numpy()\n",
    "\n",
    "\n",
    "print(f'# Particles Types Represented: {len(np.unique(tgt)) - 1}')\n",
    "print(f'# Particles Types Predicted: {len(np.unique(pred_tgt)) - 1}')\n",
    "\n",
    "\n",
    "def plot_cross_section(i):\n",
    "    plot_vol = tgt\n",
    "    plot_mask = pred_tgt\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    alpha = 0.3\n",
    "\n",
    "    # Slice at x-coordinate\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(plot_vol[i, :, :], cmap=\"viridis\")\n",
    "    plt.imshow(plot_mask[i, :, :], cmap=\"Reds\", alpha=alpha)  # Overlay mask with transparency\n",
    "    plt.title(f'Slice at x={i}')\n",
    "\n",
    "    # Slice at y-coordinate\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(plot_vol[:, i, :], cmap=\"viridis\")\n",
    "    plt.imshow(plot_mask[:, i, :], cmap=\"Reds\", alpha=alpha)\n",
    "    plt.title(f'Slice at y={i}')\n",
    "\n",
    "    # Slice at z-coordinate\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(plot_vol[:, :, i], cmap=\"viridis\")\n",
    "    plt.imshow(plot_mask[:, :, i], cmap=\"Reds\", alpha=alpha)\n",
    "    plt.title(f'Slice at z={i}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Interactive Slider for scrolling through slices\n",
    "interact(plot_cross_section, i=(0, tgt.shape[0] - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
