{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as torch_split\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "import numpy as np\n",
    "import dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler\n",
    "from monai.losses import DiceLoss\n",
    "from monai.losses import FocalLoss\n",
    "from monai.networks.nets import UNet\n",
    "import sys\n",
    "sys.path.insert(1, 'H:/Projects/Kaggle/CZII-CryoET-Object-Identification/preprocessing')\n",
    "sys.path.insert(1, 'H:/Projects/Kaggle/CZII-CryoET-Object-Identification/postprocessing')\n",
    "import visual\n",
    "\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"H:/Projects/Kaggle/CZII-CryoET-Object-Identification/datasets/3D/dim104-heat-map-700\"\n",
    "data = dataset.UNetDataset(path=path)\n",
    "\n",
    "tv_split = 0.8\n",
    "trn = int(len(data) * tv_split)\n",
    "val = len(data) - trn\n",
    "\n",
    "# train_dataset, val_dataset = torch_split.random_split(data, [trn, val])\n",
    "\n",
    "train_dataset = dataset.UNetDataset(path=path, train=True)\n",
    "val_dataset = dataset.UNetDataset(path=path, val=True)\n",
    "\n",
    "labels = [\n",
    "\"background\",\n",
    "\"apo-ferritin(E)\",\n",
    "\"beta-amylase(NS)\",\n",
    "\"beta-galactosidase(H)\",\n",
    "\"ribosome(E)\",\n",
    "\"thyroglobulin(H)\",\n",
    "\"virus-like-particle(E)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 08:17:37,592] A new study created in memory with name: no-name-b97bc9c1-8be6-4593-ad7a-82cef1a83e25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.19253355099095237\n",
      "Epoch 1 loss: 0.11746144874228372\n",
      "Epoch 2 loss: 0.0855516286359893\n",
      "Epoch 3 loss: 0.06825231264034907\n",
      "Epoch 4 loss: 0.058345901055468455\n",
      "Epoch 5 loss: 0.05078086960646841\n",
      "Epoch 6 loss: 0.04474914198120435\n",
      "Epoch 7 loss: 0.039943107300334506\n",
      "Epoch 8 loss: 0.03659689881735378\n",
      "Epoch 9 loss: 0.03378640198045307\n",
      "Epoch 10 loss: 0.0314084357685513\n",
      "Epoch 11 loss: 0.0293273131052653\n",
      "Epoch 12 loss: 0.027723345905542374\n",
      "Epoch 13 loss: 0.026302766882710986\n",
      "Epoch 14 loss: 0.02498713756601016\n",
      "Epoch 15 loss: 0.023873560337556735\n",
      "Epoch 16 loss: 0.022953530980481043\n",
      "Epoch 17 loss: 0.0220837342656321\n",
      "Epoch 18 loss: 0.021223079413175583\n",
      "Epoch 19 loss: 0.020515827875998285\n",
      "Epoch 20 loss: 0.019931494982706174\n",
      "Epoch 21 loss: 0.019347550968329113\n",
      "Epoch 22 loss: 0.018852649049626455\n",
      "Epoch 23 loss: 0.01835367062853442\n",
      "Epoch 24 loss: 0.01790864910516474\n",
      "Epoch 25 loss: 0.017505693559845287\n",
      "Epoch 26 loss: 0.017096587353282504\n",
      "Epoch 27 loss: 0.01678870576951239\n",
      "Epoch 28 loss: 0.016490701379047498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 08:52:50,073] Trial 0 finished with value: 0.016113667231467035 and parameters: {'lr': 1.985179111620316e-05, 'decay': 0.8311906302523631}. Best is trial 0 with value: 0.016113667231467035.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.016113667231467035\n",
      "Epoch 0 loss: 0.12776863078276315\n",
      "Epoch 1 loss: 0.0702606663107872\n",
      "Epoch 2 loss: 0.0479134540590975\n",
      "Epoch 3 loss: 0.03514339733454916\n",
      "Epoch 4 loss: 0.02781997538275189\n",
      "Epoch 5 loss: 0.022498129556576412\n",
      "Epoch 6 loss: 0.018812078775631055\n",
      "Epoch 7 loss: 0.016030598017904494\n",
      "Epoch 8 loss: 0.014188543893396854\n",
      "Epoch 9 loss: 0.012756804728673564\n",
      "Epoch 10 loss: 0.011563996163507303\n",
      "Epoch 11 loss: 0.010616312631302409\n",
      "Epoch 12 loss: 0.009907609472672144\n",
      "Epoch 13 loss: 0.009328823847075304\n",
      "Epoch 14 loss: 0.00882801247967614\n",
      "Epoch 15 loss: 0.008394705545571115\n",
      "Epoch 16 loss: 0.007999508020778498\n",
      "Epoch 17 loss: 0.007585719796932406\n",
      "Epoch 18 loss: 0.007507151717113124\n",
      "Epoch 19 loss: 0.0072546713054180145\n",
      "Epoch 20 loss: 0.0070174927823245525\n",
      "Epoch 21 loss: 0.006842651663141118\n",
      "Epoch 22 loss: 0.00668547638795442\n",
      "Epoch 23 loss: 0.006527445072101222\n",
      "Epoch 24 loss: 0.006465236863328351\n",
      "Epoch 25 loss: 0.00630714138969779\n",
      "Epoch 26 loss: 0.006137951225456264\n",
      "Epoch 27 loss: 0.006042448907262749\n",
      "Epoch 28 loss: 0.005882842880156305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 09:33:57,601] Trial 1 finished with value: 0.005857134858767192 and parameters: {'lr': 5.570803796931761e-05, 'decay': 0.9054139490638864}. Best is trial 1 with value: 0.005857134858767192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.005857134858767192\n",
      "Epoch 0 loss: 0.14496521486176384\n",
      "Epoch 1 loss: 0.08318402121464412\n",
      "Epoch 2 loss: 0.06092141610052851\n",
      "Epoch 3 loss: 0.048392657190561295\n",
      "Epoch 4 loss: 0.04047441358367602\n",
      "Epoch 5 loss: 0.03461386470331086\n",
      "Epoch 6 loss: 0.030011072133978207\n",
      "Epoch 7 loss: 0.026576022514038615\n",
      "Epoch 8 loss: 0.023620856718884573\n",
      "Epoch 9 loss: 0.0211964568330182\n",
      "Epoch 10 loss: 0.01915929363005691\n",
      "Epoch 11 loss: 0.017478869400090642\n",
      "Epoch 12 loss: 0.015995852028330166\n",
      "Epoch 13 loss: 0.014783072595794996\n",
      "Epoch 14 loss: 0.013623074317971865\n",
      "Epoch 15 loss: 0.012677222386830382\n",
      "Epoch 16 loss: 0.011965354904532433\n",
      "Epoch 17 loss: 0.011186282771329084\n",
      "Epoch 18 loss: 0.010672268250750171\n",
      "Epoch 19 loss: 0.010105719996823205\n",
      "Epoch 20 loss: 0.009658277655641237\n",
      "Epoch 21 loss: 0.009226037085884146\n",
      "Epoch 22 loss: 0.00888796140336328\n",
      "Epoch 23 loss: 0.008582152012321684\n",
      "Epoch 24 loss: 0.00829888621552123\n",
      "Epoch 25 loss: 0.007983543082243867\n",
      "Epoch 26 loss: 0.007808267656299803\n",
      "Epoch 27 loss: 0.007589094496021668\n",
      "Epoch 28 loss: 0.007371748901075787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 10:15:08,482] Trial 2 finished with value: 0.007185239810496569 and parameters: {'lr': 3.338928000526938e-05, 'decay': 0.9552096327693436}. Best is trial 1 with value: 0.005857134858767192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.007185239810496569\n",
      "Epoch 0 loss: 0.13957437376181284\n",
      "Epoch 1 loss: 0.07687035120195812\n",
      "Epoch 2 loss: 0.05412744316789839\n",
      "Epoch 3 loss: 0.04019901860091421\n",
      "Epoch 4 loss: 0.033688304324944816\n",
      "Epoch 5 loss: 0.028545637097623613\n",
      "Epoch 6 loss: 0.02456811649931802\n",
      "Epoch 7 loss: 0.021426697158151202\n",
      "Epoch 8 loss: 0.019622900419765048\n",
      "Epoch 9 loss: 0.018051374703645706\n",
      "Epoch 10 loss: 0.016801605621973675\n",
      "Epoch 11 loss: 0.015602102296219932\n",
      "Epoch 12 loss: 0.014801653826402294\n",
      "Epoch 13 loss: 0.014174140782819854\n",
      "Epoch 14 loss: 0.013539777758220831\n",
      "Epoch 15 loss: 0.013031380044089423\n",
      "Epoch 16 loss: 0.012704828650587134\n",
      "Epoch 17 loss: 0.012332595367398527\n",
      "Epoch 18 loss: 0.011999261048105028\n",
      "Epoch 19 loss: 0.011701410843266381\n",
      "Epoch 20 loss: 0.011495177116658952\n",
      "Epoch 21 loss: 0.011320716494487392\n",
      "Epoch 22 loss: 0.011098002394040426\n",
      "Epoch 23 loss: 0.010888134957187705\n",
      "Epoch 24 loss: 0.010785074801080756\n",
      "Epoch 25 loss: 0.010640380800598197\n",
      "Epoch 26 loss: 0.010523190100987753\n",
      "Epoch 27 loss: 0.01040055737313297\n",
      "Epoch 28 loss: 0.010304392832848761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 10:56:18,641] Trial 3 finished with value: 0.010241792744232548 and parameters: {'lr': 5.327108874232668e-05, 'decay': 0.6958264819928195}. Best is trial 1 with value: 0.005857134858767192.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.010241792744232548\n",
      "Epoch 0 loss: 0.002617563664292296\n",
      "Epoch 1 loss: 0.0015917308887259827\n",
      "Epoch 2 loss: 0.001401357042292754\n",
      "Epoch 3 loss: 0.0013980808564358288\n",
      "Epoch 4 loss: 0.001329328761332565\n",
      "Epoch 5 loss: 0.001348303449857566\n",
      "Epoch 6 loss: 0.0012468152757113178\n",
      "Epoch 7 loss: 0.0012058062970431314\n",
      "Epoch 8 loss: 0.0011929027839667266\n",
      "Epoch 9 loss: 0.0012398934147010248\n",
      "Epoch 10 loss: 0.0011928370739850733\n",
      "Epoch 11 loss: 0.0011820996878668666\n",
      "Epoch 12 loss: 0.001135827378473348\n",
      "Epoch 13 loss: 0.0012087572961010868\n",
      "Epoch 14 loss: 0.00119125302363601\n",
      "Epoch 15 loss: 0.0012852071473995845\n",
      "Epoch 16 loss: 0.0012386964064919287\n",
      "Epoch 17 loss: 0.0011681979910160105\n",
      "Epoch 18 loss: 0.001209260533667273\n",
      "Epoch 19 loss: 0.0011682885362663204\n",
      "Epoch 20 loss: 0.0012061121977037853\n",
      "Epoch 21 loss: 0.0011538946871749228\n",
      "Epoch 22 loss: 0.0011809114237419432\n",
      "Epoch 23 loss: 0.0011563727554554741\n",
      "Epoch 24 loss: 0.0011615114053711295\n",
      "Epoch 25 loss: 0.0011634438479733136\n",
      "Epoch 26 loss: 0.0011502403972877397\n",
      "Epoch 27 loss: 0.0011901683044723338\n",
      "Epoch 28 loss: 0.001133216338025199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 11:37:28,409] Trial 4 finished with value: 0.0011611692090001372 and parameters: {'lr': 0.005244172927782109, 'decay': 0.7763730170145892}. Best is trial 4 with value: 0.0011611692090001372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011611692090001372\n",
      "Epoch 0 loss: 0.012569226841959689\n",
      "Epoch 1 loss: 0.004776301586793529\n",
      "Epoch 2 loss: 0.0031629976712995106\n",
      "Epoch 3 loss: 0.002359948871243331\n",
      "Epoch 4 loss: 0.0020237166124085584\n",
      "Epoch 5 loss: 0.0017405294994306234\n",
      "Epoch 6 loss: 0.001632227575302952\n",
      "Epoch 7 loss: 0.0014738697532771362\n",
      "Epoch 8 loss: 0.00140201511223697\n",
      "Epoch 9 loss: 0.001395413716737595\n",
      "Epoch 10 loss: 0.0013608189765363932\n",
      "Epoch 11 loss: 0.0012903701410525376\n",
      "Epoch 12 loss: 0.001265456007483105\n",
      "Epoch 13 loss: 0.0012655214199589358\n",
      "Epoch 14 loss: 0.0012456391575849718\n",
      "Epoch 15 loss: 0.001270177825871441\n",
      "Epoch 16 loss: 0.0012067029278518425\n",
      "Epoch 17 loss: 0.0012134651058456963\n",
      "Epoch 18 loss: 0.0012070256052538753\n",
      "Epoch 19 loss: 0.0012065911691428886\n",
      "Epoch 20 loss: 0.0012052830231065552\n",
      "Epoch 21 loss: 0.001196594300886823\n",
      "Epoch 22 loss: 0.0011970124647228254\n",
      "Epoch 23 loss: 0.0012215827333016528\n",
      "Epoch 24 loss: 0.001197314420197573\n",
      "Epoch 25 loss: 0.0011806176690798667\n",
      "Epoch 26 loss: 0.0011773182518987192\n",
      "Epoch 27 loss: 0.001186138820937938\n",
      "Epoch 28 loss: 0.0011726957099098298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 12:18:37,006] Trial 5 finished with value: 0.0011725822696462274 and parameters: {'lr': 0.001101049695775549, 'decay': 0.6771688198855408}. Best is trial 4 with value: 0.0011611692090001372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011725822696462274\n",
      "Epoch 0 loss: 0.0045801033783290125\n",
      "Epoch 1 loss: 0.0018830505303210681\n",
      "Epoch 2 loss: 0.001472932260690464\n",
      "Epoch 3 loss: 0.0013413692488231594\n",
      "Epoch 4 loss: 0.0013296226065398918\n",
      "Epoch 5 loss: 0.0013706048743592368\n",
      "Epoch 6 loss: 0.001258664428152972\n",
      "Epoch 7 loss: 0.0012234435028706987\n",
      "Epoch 8 loss: 0.001536592595382697\n",
      "Epoch 9 loss: 0.001192740294047528\n",
      "Epoch 10 loss: 0.0012011510035437015\n",
      "Epoch 11 loss: 0.0012051386422374183\n",
      "Epoch 12 loss: 0.0011795333250322277\n",
      "Epoch 13 loss: 0.0013317544039131866\n",
      "Epoch 14 loss: 0.0011477803992521432\n",
      "Epoch 15 loss: 0.0011524789863162571\n",
      "Epoch 16 loss: 0.001156322670997017\n",
      "Epoch 17 loss: 0.001172014059395426\n",
      "Epoch 18 loss: 0.0012235795147717\n",
      "Epoch 19 loss: 0.001153442374844518\n",
      "Epoch 20 loss: 0.0011591700345484747\n",
      "Epoch 21 loss: 0.0011715947184711695\n",
      "Epoch 22 loss: 0.001152068467086388\n",
      "Epoch 23 loss: 0.0011788118734127944\n",
      "Epoch 24 loss: 0.0011584747763764528\n",
      "Epoch 25 loss: 0.0011503631507770882\n",
      "Epoch 26 loss: 0.0011625805378167166\n",
      "Epoch 27 loss: 0.0011451472786979543\n",
      "Epoch 28 loss: 0.001160100192969872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 12:59:52,102] Trial 6 finished with value: 0.0011773365032341746 and parameters: {'lr': 0.0031859780971462727, 'decay': 0.5757470121809716}. Best is trial 4 with value: 0.0011611692090001372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011773365032341746\n",
      "Epoch 0 loss: 0.020174656477239396\n",
      "Epoch 1 loss: 0.009477922692894936\n",
      "Epoch 2 loss: 0.006409192871716287\n",
      "Epoch 3 loss: 0.005192306979248921\n",
      "Epoch 4 loss: 0.005021288318352567\n",
      "Epoch 5 loss: 0.0047052098541624015\n",
      "Epoch 6 loss: 0.004313412277648847\n",
      "Epoch 7 loss: 0.0040937479999330305\n",
      "Epoch 8 loss: 0.003958403805477751\n",
      "Epoch 9 loss: 0.0038201044468830028\n",
      "Epoch 10 loss: 0.0037131483097457224\n",
      "Epoch 11 loss: 0.0035327374417748717\n",
      "Epoch 12 loss: 0.0035114098185052476\n",
      "Epoch 13 loss: 0.0034429612052109507\n",
      "Epoch 14 loss: 0.003356244104603926\n",
      "Epoch 15 loss: 0.003303590980875823\n",
      "Epoch 16 loss: 0.003262213250208232\n",
      "Epoch 17 loss: 0.0032344156514025396\n",
      "Epoch 18 loss: 0.0032018463179055187\n",
      "Epoch 19 loss: 0.003172205062583089\n",
      "Epoch 20 loss: 0.003148844413873222\n",
      "Epoch 21 loss: 0.0031371175621946654\n",
      "Epoch 22 loss: 0.003117726262037953\n",
      "Epoch 23 loss: 0.0030894804642432267\n",
      "Epoch 24 loss: 0.0030890077662964663\n",
      "Epoch 25 loss: 0.003078323426759905\n",
      "Epoch 26 loss: 0.003071160133307179\n",
      "Epoch 27 loss: 0.003060681564319465\n",
      "Epoch 28 loss: 0.0030589362140744925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 13:41:24,014] Trial 7 finished with value: 0.003053103056218889 and parameters: {'lr': 0.0005691122332540043, 'decay': 0.4547819980244929}. Best is trial 4 with value: 0.0011611692090001372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.003053103056218889\n",
      "Epoch 0 loss: 0.012631095324953398\n",
      "Epoch 1 loss: 0.00647738017141819\n",
      "Epoch 2 loss: 0.004115346301760938\n",
      "Epoch 3 loss: 0.0032472173786825603\n",
      "Epoch 4 loss: 0.003110942534274525\n",
      "Epoch 5 loss: 0.002726926908103956\n",
      "Epoch 6 loss: 0.002297153334236807\n",
      "Epoch 7 loss: 0.0020429656013018554\n",
      "Epoch 8 loss: 0.0018450046837743786\n",
      "Epoch 9 loss: 0.0016636449662554595\n",
      "Epoch 10 loss: 0.0015061203157529235\n",
      "Epoch 11 loss: 0.0014313582279202011\n",
      "Epoch 12 loss: 0.0013803258900427157\n",
      "Epoch 13 loss: 0.0013411035761237144\n",
      "Epoch 14 loss: 0.0013186566454047959\n",
      "Epoch 15 loss: 0.0012991020533566673\n",
      "Epoch 16 loss: 0.0012836767645138833\n",
      "Epoch 17 loss: 0.0012739461122287645\n",
      "Epoch 18 loss: 0.0012659617415111926\n",
      "Epoch 19 loss: 0.0012585670143986742\n",
      "Epoch 20 loss: 0.0012536135295199023\n",
      "Epoch 21 loss: 0.0012500029341835114\n",
      "Epoch 22 loss: 0.0012511391865296497\n",
      "Epoch 23 loss: 0.0012407718329793876\n",
      "Epoch 24 loss: 0.0013750515257318814\n",
      "Epoch 25 loss: 0.0012558915833425191\n",
      "Epoch 26 loss: 0.001239329615297417\n",
      "Epoch 27 loss: 0.0012326276628300548\n",
      "Epoch 28 loss: 0.0012321781703374451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 14:22:54,155] Trial 8 finished with value: 0.0012274232511926028 and parameters: {'lr': 0.0007409412215398597, 'decay': 0.6582337496026821}. Best is trial 4 with value: 0.0011611692090001372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0012274232511926028\n",
      "Epoch 0 loss: 0.002181144534713692\n",
      "Epoch 1 loss: 0.0014833345259022382\n",
      "Epoch 2 loss: 0.0014102250311730637\n",
      "Epoch 3 loss: 0.0012770439110075433\n",
      "Epoch 4 loss: 0.0011846806802269486\n",
      "Epoch 5 loss: 0.001106404712320202\n",
      "Epoch 6 loss: 0.0013088308041915298\n",
      "Epoch 7 loss: 0.0011372130959191257\n",
      "Epoch 8 loss: 0.0014295492761044039\n",
      "Epoch 9 loss: 0.0011541202483284804\n",
      "Epoch 10 loss: 0.0011516613497709234\n",
      "Epoch 11 loss: 0.001129748791249262\n",
      "Epoch 12 loss: 0.0013300058069742387\n",
      "Epoch 13 loss: 0.001127000445396536\n",
      "Epoch 14 loss: 0.001168181563520597\n",
      "Epoch 15 loss: 0.0011331621660954421\n",
      "Epoch 16 loss: 0.0011574560129601094\n",
      "Epoch 17 loss: 0.0011477165389806032\n",
      "Epoch 18 loss: 0.0011337480326700541\n",
      "Epoch 19 loss: 0.0012315994956427151\n",
      "Epoch 20 loss: 0.0010832372742394607\n",
      "Epoch 21 loss: 0.0011440766716582908\n",
      "Epoch 22 loss: 0.0011483490492941604\n",
      "Epoch 23 loss: 0.00117105211959117\n",
      "Epoch 24 loss: 0.0011433824482891294\n",
      "Epoch 25 loss: 0.00114957919706487\n",
      "Epoch 26 loss: 0.0011455438022191327\n",
      "Epoch 27 loss: 0.0011425146238050526\n",
      "Epoch 28 loss: 0.001141390181146562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 15:04:27,416] Trial 9 finished with value: 0.0011574472818109724 and parameters: {'lr': 0.005551990087504371, 'decay': 0.7834123529246597}. Best is trial 9 with value: 0.0011574472818109724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011574472818109724\n",
      "Epoch 0 loss: 0.0636355761024687\n",
      "Epoch 1 loss: 0.031351566314697266\n",
      "Epoch 2 loss: 0.018599496119552188\n",
      "Epoch 3 loss: 0.012339744199481275\n",
      "Epoch 4 loss: 0.01159827493959003\n",
      "Epoch 5 loss: 0.010680551123287942\n",
      "Epoch 6 loss: 0.009842776382962862\n",
      "Epoch 7 loss: 0.009148856004079184\n",
      "Epoch 8 loss: 0.008994325271083249\n",
      "Epoch 9 loss: 0.008789121587243345\n",
      "Epoch 10 loss: 0.008652645266718335\n",
      "Epoch 11 loss: 0.008477320584158102\n",
      "Epoch 12 loss: 0.00844869731614987\n",
      "Epoch 13 loss: 0.008383675685359372\n",
      "Epoch 14 loss: 0.008340236006511582\n",
      "Epoch 15 loss: 0.008280024863779545\n",
      "Epoch 16 loss: 0.008263207040727139\n",
      "Epoch 17 loss: 0.008245172703431712\n",
      "Epoch 18 loss: 0.008224173759420713\n",
      "Epoch 19 loss: 0.008207325409683917\n",
      "Epoch 20 loss: 0.008201555969814459\n",
      "Epoch 21 loss: 0.008193967760437064\n",
      "Epoch 22 loss: 0.008192367955214448\n",
      "Epoch 23 loss: 0.008184544742107391\n",
      "Epoch 24 loss: 0.008181578376226954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 15:40:27,851] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 loss: 0.00817828563352426\n",
      "Epoch 0 loss: 0.002548650916044911\n",
      "Epoch 1 loss: 0.0015204038289893004\n",
      "Epoch 2 loss: 0.0014536830130964518\n",
      "Epoch 3 loss: 0.0013247893140133885\n",
      "Epoch 4 loss: 0.0013168415235769418\n",
      "Epoch 5 loss: 0.0012680907578517993\n",
      "Epoch 6 loss: 0.0012674243060044115\n",
      "Epoch 7 loss: 0.0012376239368071158\n",
      "Epoch 8 loss: 0.0012534467063637243\n",
      "Epoch 9 loss: 0.0011989697813987732\n",
      "Epoch 10 loss: 0.0012212698994618324\n",
      "Epoch 11 loss: 0.0012115536438715127\n",
      "Epoch 12 loss: 0.001230463191556434\n",
      "Epoch 13 loss: 0.0012178942043748167\n",
      "Epoch 14 loss: 0.0011936822750916083\n",
      "Epoch 15 loss: 0.00121944321371201\n",
      "Epoch 16 loss: 0.001185157659670545\n",
      "Epoch 17 loss: 0.0012083734489149517\n",
      "Epoch 18 loss: 0.0012094286761970983\n",
      "Epoch 19 loss: 0.0012080181881578432\n",
      "Epoch 20 loss: 0.0012048023701128033\n",
      "Epoch 21 loss: 0.0012054163833252257\n",
      "Epoch 22 loss: 0.0012034817158968912\n",
      "Epoch 23 loss: 0.0012082884269249109\n",
      "Epoch 24 loss: 0.001198284172763427\n",
      "Epoch 25 loss: 0.0012029361419586672\n",
      "Epoch 26 loss: 0.00119883398939338\n",
      "Epoch 27 loss: 0.0011946441760907571\n",
      "Epoch 28 loss: 0.0012073421514489585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 16:10:54,255] Trial 11 finished with value: 0.0012119046101967494 and parameters: {'lr': 0.009468346119167576, 'decay': 0.8065984387396006}. Best is trial 9 with value: 0.0011574472818109724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0012119046101967494\n",
      "Epoch 0 loss: 0.0031825969668312203\n",
      "Epoch 1 loss: 0.0016667084483843711\n",
      "Epoch 2 loss: 0.0014842938010891278\n",
      "Epoch 3 loss: 0.001406044893277188\n",
      "Epoch 4 loss: 0.0013566331989649269\n",
      "Epoch 5 loss: 0.001356084507683085\n",
      "Epoch 6 loss: 0.0012918708121611013\n",
      "Epoch 7 loss: 0.0012603185734608108\n",
      "Epoch 8 loss: 0.0012524734095980723\n",
      "Epoch 9 loss: 0.001263446834248801\n",
      "Epoch 10 loss: 0.0012447252714385588\n",
      "Epoch 11 loss: 0.0012429477517596548\n",
      "Epoch 12 loss: 0.0012111689688430892\n",
      "Epoch 13 loss: 0.001242546713910997\n",
      "Epoch 14 loss: 0.001212845297737254\n",
      "Epoch 15 loss: 0.0012122316725759043\n",
      "Epoch 16 loss: 0.0012300401641469863\n",
      "Epoch 17 loss: 0.0012246422573096221\n",
      "Epoch 18 loss: 0.0012191887944936752\n",
      "Epoch 19 loss: 0.001214551027967698\n",
      "Epoch 20 loss: 0.0012279079399175113\n",
      "Epoch 21 loss: 0.0012170225123150481\n",
      "Epoch 22 loss: 0.0012200281360290116\n",
      "Epoch 23 loss: 0.0012156084930110308\n",
      "Epoch 24 loss: 0.0012264238773948615\n",
      "Epoch 25 loss: 0.0012220314755621883\n",
      "Epoch 26 loss: 0.0012224519677046272\n",
      "Epoch 27 loss: 0.0012223470257595181\n",
      "Epoch 28 loss: 0.0012190905528970892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 16:40:21,801] Trial 12 finished with value: 0.0012202517051870625 and parameters: {'lr': 0.009536306028847988, 'decay': 0.7689268167827322}. Best is trial 9 with value: 0.0011574472818109724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0012202517051870625\n",
      "Epoch 0 loss: 0.004283553817205959\n",
      "Epoch 1 loss: 0.0020860470831394196\n",
      "Epoch 2 loss: 0.0016491394360653227\n",
      "Epoch 3 loss: 0.00145602409934832\n",
      "Epoch 4 loss: 0.0013419203460216522\n",
      "Epoch 5 loss: 0.0013056227083628376\n",
      "Epoch 6 loss: 0.0015295806547833814\n",
      "Epoch 7 loss: 0.0012149725161078903\n",
      "Epoch 8 loss: 0.0012130258449663718\n",
      "Epoch 9 loss: 0.001493973334112929\n",
      "Epoch 10 loss: 0.0011917426406095426\n",
      "Epoch 11 loss: 0.0011895516137075094\n",
      "Epoch 12 loss: 0.0011746768141165376\n",
      "Epoch 13 loss: 0.0011893852950177258\n",
      "Epoch 14 loss: 0.00119099041654004\n",
      "Epoch 15 loss: 0.0011821709987190035\n",
      "Epoch 16 loss: 0.0011950746411457658\n",
      "Epoch 17 loss: 0.0011643320839438173\n",
      "Epoch 18 loss: 0.0011648871263282166\n",
      "Epoch 19 loss: 0.0011714657044245137\n",
      "Epoch 20 loss: 0.0011688937407193913\n",
      "Epoch 21 loss: 0.0011638964836796124\n",
      "Epoch 22 loss: 0.0011962611719758974\n",
      "Epoch 23 loss: 0.0011593359134470422\n",
      "Epoch 24 loss: 0.0011825534877263838\n",
      "Epoch 25 loss: 0.001156240649935272\n",
      "Epoch 26 loss: 0.0011559965399404366\n",
      "Epoch 27 loss: 0.0011589746767034133\n",
      "Epoch 28 loss: 0.001178003821728958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 17:09:45,824] Trial 13 finished with value: 0.0011657905350956651 and parameters: {'lr': 0.0026096063451923196, 'decay': 0.5497714600593803}. Best is trial 9 with value: 0.0011574472818109724.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011657905350956651\n",
      "Epoch 0 loss: 0.004487482365220785\n",
      "Epoch 1 loss: 0.001796971993624336\n",
      "Epoch 2 loss: 0.0016902048502945239\n",
      "Epoch 3 loss: 0.00145911466744211\n",
      "Epoch 4 loss: 0.001348349201079044\n",
      "Epoch 5 loss: 0.0013644146965816617\n",
      "Epoch 6 loss: 0.0014046015373120706\n",
      "Epoch 7 loss: 0.0012314291282867391\n",
      "Epoch 8 loss: 0.0011510178188069\n",
      "Epoch 9 loss: 0.0012408006134339506\n",
      "Epoch 10 loss: 0.0011759605258703232\n",
      "Epoch 11 loss: 0.0011675529337177675\n",
      "Epoch 12 loss: 0.001213257330366307\n",
      "Epoch 13 loss: 0.0011952105236964093\n",
      "Epoch 14 loss: 0.0011354746012431052\n",
      "Epoch 15 loss: 0.0011834693788033393\n",
      "Epoch 16 loss: 0.0011553307219098012\n",
      "Epoch 17 loss: 0.001131662762620383\n",
      "Epoch 18 loss: 0.0013113769236952066\n",
      "Epoch 19 loss: 0.0010872208772020207\n",
      "Epoch 20 loss: 0.0011378138895250028\n",
      "Epoch 21 loss: 0.0015075804096543128\n",
      "Epoch 22 loss: 0.0012620626690073146\n",
      "Epoch 23 loss: 0.0011597041221749452\n",
      "Epoch 24 loss: 0.0011706815437517231\n",
      "Epoch 25 loss: 0.0011806942315565215\n",
      "Epoch 26 loss: 0.0011278611556109455\n",
      "Epoch 27 loss: 0.0015315879653725359\n",
      "Epoch 28 loss: 0.0010708338296454814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 17:39:10,991] Trial 14 finished with value: 0.0011473140912130475 and parameters: {'lr': 0.0031310830139417182, 'decay': 0.8847056169377736}. Best is trial 14 with value: 0.0011473140912130475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 loss: 0.0011473140912130475\n",
      "Best hyperparameters: {'lr': 0.0031310830139417182, 'decay': 0.8847056169377736}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # ------------------------------ #\n",
    "    #        HYPERPARAMETERS         #\n",
    "    # ------------------------------ #\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    decay = trial.suggest_float('decay', 0.3, 1.0)\n",
    "    # dropout = trial.suggest_float(\"dropout\", 0.25, 0.5)\n",
    "    dropout = 0.3\n",
    "    # regularization_strength = trial.suggest_float(\"regularization_strength\", 1e-4, 1e-2, log=True)\n",
    "    # alpha = trial.suggest_float(\"alpha\", 0.25, 1.0)\n",
    "    # theta = trial.suggest_float(\"theta\", 0.1, 0.9)\n",
    "    # theta = 0.6\n",
    "    # gamma = trial.suggest_float(\"gamma\", 2.0, 5.0)\n",
    "    \n",
    "    # Model initialization\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=7,\n",
    "        channels=(64, 128, 256, 512),\n",
    "        strides=(2, 2, 2),\n",
    "        num_res_units=2,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "    \n",
    "    num_epochs = 30\n",
    "    batch_size = 16\n",
    "\n",
    "    # ------------------------------ #\n",
    "    #        TRAINING METHODS        #\n",
    "    # ------------------------------ #\n",
    "    weights = torch.tensor([0.0434743, 1.16546, 1.1661, 1.16513, 1.14281, 1.15554, 1.16149]).to(device)  # Example weights for classes\n",
    "\n",
    "    # dice_loss = DiceLoss(to_onehot_y=False, softmax=True, weight=weights).to(device)\n",
    "    # focal_loss = FocalLoss(to_onehot_y=False, use_softmax=True, weight=weights, gamma=gamma ).to(device)\n",
    "    mse_loss = nn.MSELoss(reduction='none')\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=decay)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=False, num_workers=4)\n",
    "\n",
    "    def add_regularization_loss(model, regularization_type, regularization_strength):\n",
    "        reg_loss = 0\n",
    "        for param in model.parameters():\n",
    "            reg_loss += torch.sum(param ** 2)\n",
    "        return regularization_strength * reg_loss\n",
    "\n",
    "    # ------------------------------ #\n",
    "    #             TRAIN              #\n",
    "    # ------------------------------ #\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input, target = batch['src'].to(device), batch['tgt'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            # loss = (theta) * dice_loss(outputs, targets) + (1 - theta) * focal_loss(outputs, targets)\n",
    "            indv_loss = mse_loss(output, target)\n",
    "            weighted_loss = (indv_loss * weights.view(1, -1, 1, 1, 1)).mean()\n",
    "            loss = weighted_loss\n",
    "            \n",
    "            # reg_loss = add_regularization_loss(model, \"L2\", regularization_strength)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "            \n",
    "        # ---------- #\n",
    "        # VALIDATION #\n",
    "        # ---------- #\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input, target = batch['src'].float().to(device), batch['tgt'].long().to(device)\n",
    "                output = model(input)\n",
    "                # loss = (theta) * dice_loss(outputs, targets) + (1 - theta) * focal_loss(outputs, targets)\n",
    "                loss = mse_loss(output, target)\n",
    "                weighted_loss = (loss * weights.view(1, -1, 1, 1, 1)).mean()\n",
    "                val_loss += weighted_loss.item()\n",
    "                \n",
    "        # print(\"batch done\")\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        trial.report(val_loss, epoch)\n",
    "        print(f\"Epoch {epoch} loss: {val_loss}\")\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            \n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "n_epochs = 25\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=MedianPruner(n_startup_trials=4, n_warmup_steps=25))\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.6432971689436171\n",
      "Epoch 1 loss: 0.5598176187939115\n",
      "Epoch 2 loss: 0.5357193417019315\n",
      "Epoch 3 loss: 0.5257072117593553\n",
      "Epoch 4 loss: 0.525143735938602\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     67\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28minput\u001b[39m, target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtgt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     70\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\hmhor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "vis = visual.loss_precision_recall(20, labels, 2.0)\n",
    "vis.start()\n",
    "vis.new_trial()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------ #\n",
    "#        HYPERPARAMETERS         #\n",
    "# ------------------------------ #\n",
    "lr = 5.0e-4\n",
    "decay = 0.9\n",
    "# dropout = trial.suggest_float(\"dropout\", 0.25, 0.5)\n",
    "dropout = 0.3\n",
    "regularization_strength = 1e-3\n",
    "# alpha = trial.suggest_float(\"alpha\", 0.25, 1.0)\n",
    "# theta = trial.suggest_float(\"theta\", 0.1, 0.9)\n",
    "theta = 0.5\n",
    "# gamma = trial.suggest_float(\"gamma\", 2.0, 5.0)\n",
    "gamma = 4.0\n",
    "# Model initialization\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(64, 128, 256, 512),\n",
    "    strides=(2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout=dropout,\n",
    ").to(device)\n",
    "\n",
    "num_epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "# ------------------------------ #\n",
    "#        TRAINING METHODS        #\n",
    "# ------------------------------ #\n",
    "weights = torch.tensor([0.0434743, 1.16546, 1.1661, 1.16513, 1.14281, 1.15554, 1.16149]).to(device)  # Example weights for classes\n",
    "# weights = torch.tensor([1.0,1.0,1.0,1.0,1.0,1.0,1.0])\n",
    "dice_loss = DiceLoss(to_onehot_y=False, softmax=True, weight=weights).to(device)\n",
    "focal_loss = FocalLoss(to_onehot_y=False, use_softmax=True, weight=weights, gamma=gamma ).to(device)\n",
    "# mse_loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=decay)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=dataset.collate_fn, shuffle=False, num_workers=4)\n",
    "\n",
    "def add_regularization_loss(model, regularization_strength):\n",
    "    reg_loss = 0\n",
    "    for param in model.parameters():\n",
    "        reg_loss += torch.sum(param ** 2)\n",
    "    return regularization_strength * reg_loss\n",
    "\n",
    "# ------------------------------ #\n",
    "#             TRAIN              #\n",
    "# ------------------------------ #\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input, target = batch['src'].to(device), batch['tgt'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = (theta) * dice_loss(output, target) + (1 - theta) * focal_loss(output, target)\n",
    "        reg_loss = add_regularization_loss(model, regularization_strength)\n",
    "        loss += reg_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "        \n",
    "    # ---------- #\n",
    "    # VALIDATION #\n",
    "    # ---------- #\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    precision = torch.zeros((7))\n",
    "    recall = torch.zeros((7))\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input, target = batch['src'].float().to(device), batch['tgt'].long().to(device)\n",
    "            output = model(input)\n",
    "            loss = (theta) * dice_loss(output, target) + (1 - theta) * focal_loss(output, target)\n",
    "            reg_loss = add_regularization_loss(model, regularization_strength)\n",
    "            loss += reg_loss\n",
    "            val_loss += loss.item()\n",
    "            p, r = metrics.continuous_precision_recall(target.to('cpu'), torch.softmax(output.to('cpu'), dim=1))\n",
    "            precision += p\n",
    "            recall += r\n",
    "    val_loss /= len(val_loader)\n",
    "    pr = torch.stack([precision, recall], dim=0)\n",
    "    vis.report(val_loss, pr)\n",
    "            \n",
    "    print(f\"Epoch {epoch} loss: {val_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"HeatNet-1-0.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "import sys\n",
    "sys.path.insert(1, 'H:/Projects/Kaggle/CZII-CryoET-Object-Identification/preprocessing')\n",
    "import load\n",
    "import augment\n",
    "import os\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "import numpy as np\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "run = 'TS_6_4'\n",
    "root = load.get_root()\n",
    "picks = load.get_picks_dict(root)\n",
    "vol, coords, scales = load.get_run_volume_picks(root, run=run, level=0)\n",
    "for key in coords.keys():\n",
    "    coords[key] = np.array(coords[key], dtype=np.int16)\n",
    "coord_list = []\n",
    "for key in coords.keys():\n",
    "    coord_list.append(coords[key])\n",
    "radii = [ 6,\n",
    "          6,\n",
    "          9,\n",
    "          15,\n",
    "          13,\n",
    "          14 ]\n",
    "params = augment.aug_params\n",
    "params[\"final_size\"] = (104,104,104)\n",
    "params[\"flip_prob\"] = 0.0\n",
    "params[\"patch_size\"] = (104,104,104)\n",
    "params[\"rot_prob\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = load.create_exponential_heatmap_gpu(6, vol.shape, coord_list, radii).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape torch.Size([104, 104, 104])\n",
      "tgt shape (7, 104, 104, 104)\n",
      "pred shape (7, 104, 104, 104)\n"
     ]
    }
   ],
   "source": [
    "sample = augment.random_augmentation_gpu(vol, \n",
    "                                mask,\n",
    "                                num_samples=1, \n",
    "                                aug_params=params\n",
    "                                )\n",
    "\n",
    "src = sample[0][\"source\"].unsqueeze(0).to(device)\n",
    "tgt = sample[0][\"target\"].unsqueeze(0).to(device)\n",
    "\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=7,\n",
    "    channels=(64, 128, 256, 512),\n",
    "    strides=(2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"HeatNet-1-0.pth\"))\n",
    "\n",
    "model.eval()\n",
    "pred = torch.softmax(model(src), dim=1).to('cpu')\n",
    "pred = pred.squeeze().to('cpu').detach().numpy()\n",
    "src = src.to('cpu').squeeze()\n",
    "tgt = tgt.squeeze(0).to('cpu').detach().numpy()\n",
    "print(f\"src shape {src.shape}\")\n",
    "print(f\"tgt shape {tgt.shape}\")\n",
    "print(f\"pred shape {pred.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b94e9db106c4c7d8a7e508f55c338e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='i', max=103), Output()), _dom_classes=('widget-interact…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_cross_section(i)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "\n",
    "def plot_cross_section(i):\n",
    "    vol1 = 1.0 - src\n",
    "    vol1 = np.zeros(pred[0].shape)\n",
    "    vol2 = pred[1]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    alpha = 0.3\n",
    "\n",
    "    # Slice at x-coordinate\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(vol1[i, :, :], cmap=\"viridis\", alpha=alpha)\n",
    "    plt.imshow(vol2[i, :, :], cmap=\"Reds\", alpha=alpha)  # Overlay mask with transparency\n",
    "    plt.title(f'Slice at x={i}')\n",
    "\n",
    "    # Slice at y-coordinate\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(vol1[:, i, :], cmap=\"viridis\", alpha=alpha)\n",
    "    plt.imshow(vol2[:, i, :], cmap=\"Blues\", alpha=alpha)\n",
    "    plt.title(f'Slice at y={i}')\n",
    "\n",
    "    # Slice at z-coordinate\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(vol1[:, :, i], cmap=\"viridis\", alpha=alpha)\n",
    "    plt.imshow(vol2[:, :, i], cmap=\"Reds\", alpha=alpha)\n",
    "    plt.title(f'Slice at z={i}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Interactive Slider for scrolling through slices\n",
    "interact(plot_cross_section, i=(0, src.shape[0] - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
